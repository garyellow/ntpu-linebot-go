# ==============================================================================
# Full Stack Deployment Configuration
# Bot + Prometheus + Grafana + Alertmanager (internal Docker network)
# ==============================================================================

# LINE Bot Configuration (Required)
LINE_CHANNEL_ACCESS_TOKEN=your_access_token_here
LINE_CHANNEL_SECRET=your_channel_secret_here

# LLM Configuration (Optional - at least one API key required for NLU features)
# Enables NLU intent parsing and query expansion
# Get Gemini API key from: https://aistudio.google.com/apikey
# Get Groq API key from: https://console.groq.com/keys
# Get Cerebras API key from: https://cloud.cerebras.ai/
#GEMINI_API_KEY=your_gemini_api_key_here
#GROQ_API_KEY=your_groq_api_key_here
#CEREBRAS_API_KEY=your_cerebras_api_key_here

# LLM Provider Selection (Optional)
# Comma-separated list of providers for automatic fallback (default: gemini,groq,cerebras)
# Only providers with valid API keys will be used
#LLM_PROVIDERS=gemini,groq,cerebras

# LLM Model Configuration (Optional - comma-separated fallback chain)
# First model is primary, rest are fallbacks tried in order
#GEMINI_INTENT_MODELS=gemini-2.5-flash,gemini-2.5-flash-lite
#GEMINI_EXPANDER_MODELS=gemini-2.5-flash,gemini-2.5-flash-lite
#GROQ_INTENT_MODELS=meta-llama/llama-4-maverick-17b-128e-instruct,llama-3.3-70b-versatile
#GROQ_EXPANDER_MODELS=meta-llama/llama-4-scout-17b-16e-instruct,llama-3.1-8b-instant
#CEREBRAS_INTENT_MODELS=llama-3.3-70b,llama-3.1-8b
#CEREBRAS_EXPANDER_MODELS=llama-3.3-70b,llama-3.1-8b

# Docker Configuration
#IMAGE_TAG=latest
#HOST_PORT=10000

# Server Configuration
#PORT=10000
#LOG_LEVEL=info
#DATA_DIR=/data
#CACHE_TTL=168h
#SHUTDOWN_TIMEOUT=30s

# Scraper Configuration
#SCRAPER_TIMEOUT=60s
#SCRAPER_MAX_RETRIES=10

# Webhook Configuration
#WEBHOOK_TIMEOUT=60s

# Rate Limit Configuration
# User: 15 burst, 0.1 tokens/sec (1 per 10s)
#USER_RATE_BURST=15
#USER_RATE_REFILL=0.1
# LLM: 60 burst, 30/hr refill, 180/day sliding window
#LLM_RATE_BURST=60
#LLM_RATE_REFILL=30
#LLM_RATE_DAILY=180
# Global: 100 requests per second
#GLOBAL_RATE_RPS=100

# Metrics Authentication (Internal network - disabled by default)
# Leave METRICS_PASSWORD empty for internal Docker network (no auth needed)
METRICS_USERNAME=prometheus
METRICS_PASSWORD=

# Monitoring Ports (exposed to host)
#GRAFANA_PORT=3000
#PROMETHEUS_PORT=9090
#ALERTMANAGER_PORT=9093

# Grafana Configuration
GRAFANA_USER=admin
GRAFANA_PASSWORD=admin123
